{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS W261 Machine Learning At Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Christopher Llop | christopher.llop@ischool.berkeley.edu <br>\n",
    "Week 4 | Submission Date: 9/29/2015\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>HW4.0.</b>\n",
    "What is MrJob? How is it different to Hadoop MapReduce? \n",
    "What are the mapper_final(), combiner_final(), reducer_final() methods? When are they called?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<span style=\"color:green\"><b>Answer:</b></span>\n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>HW4.1. </b>\n",
    "\n",
    "What is serialization in the context of MrJob or Hadoop? \n",
    "When it used in these frameworks? \n",
    "What is the default serialization mode for input and outputs for MrJob? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"><b>Answer:</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>HW4.2</b>\n",
    "\n",
    "Recall the Microsoft logfiles data from the async lecture. The logfiles are described are located at:\n",
    "\n",
    "https://kdd.ics.uci.edu/databases/msweb/msweb.html\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/anonymous/\n",
    "\n",
    "This dataset records which areas (Vroots) of www.microsoft.com each user visited in a one-week timeframe in Feburary 1998.\n",
    "\n",
    " Here, you must preprocess the data on a single node (i.e., not on a cluster of nodes) from the format:\n",
    "\n",
    "C,\"10001\",10001   #Visitor id 10001\n",
    "V,1000,1          #Visit by Visitor 10001 to page id 1000\n",
    "V,1001,1          #Visit by Visitor 10001 to page id 1001\n",
    "V,1002,1          #Visit by Visitor 10001 to page id 1002\n",
    "C,\"10002\",10002   #Visitor id 10001\n",
    "V\n",
    "Note: #denotes comments\n",
    "to the format:\n",
    "\n",
    "V,1000,1,C, 10001\n",
    "V,1001,1,C, 10001\n",
    "V,1002,1,C, 10001\n",
    "\n",
    "Write the python code to accomplish this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>HW 4.3</b> \n",
    "\n",
    "Find the 5 most frequently visited pages using mrjob from the output of 4.2 (i.e., transfromed log file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>HW4.4</b>\n",
    "\n",
    "\n",
    "Find the most frequent visitor of each page using mrjob and the output of 4.2  (i.e., transfromed log file). In this output please include the webpage URL, webpageID and Visitor ID.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>HW 4.5</b>\n",
    "\n",
    "Here you will use a different dataset consisting of word-frequency distributions \n",
    "for 1,000 Twitter users. These Twitter users use language in very different ways,\n",
    "and were classified by hand according to the criteria:\n",
    "\n",
    "0: Human, where only basic human-human communication is observed.\n",
    "\n",
    "1: Cyborg, where language is primarily borrowed from other sources\n",
    "(e.g., jobs listings, classifieds postings, advertisements, etc...).\n",
    "\n",
    "2: Robot, where language is formulaically derived from unrelated sources\n",
    "(e.g., weather/seismology, police/fire event logs, etc...).\n",
    "\n",
    "3: Spammer, where language is replicated to high multiplicity\n",
    "(e.g., celebrity obsessions, personal promotion, etc... )\n",
    "\n",
    "Check out the preprints of our recent research,\n",
    "which spawned this dataset:\n",
    "\n",
    "http://arxiv.org/abs/1505.04342\n",
    "http://arxiv.org/abs/1508.01843\n",
    "\n",
    "The main data lie in the accompanying file:\n",
    "\n",
    "topUsers_Apr-Jul_2014_1000-words.txt\n",
    "\n",
    "and are of the form:\n",
    "\n",
    "USERID,CODE,TOTAL,WORD1_COUNT,WORD2_COUNT,...\n",
    ".\n",
    ".\n",
    "\n",
    "where\n",
    "\n",
    "USERID = unique user identifier\n",
    "CODE = 0/1/2/3 class code\n",
    "TOTAL = sum of the word counts\n",
    "\n",
    "Using this data, you will implement a 1000-dimensional K-means algorithm on the users\n",
    "by their 1000-dimensional word stripes/vectors using several \n",
    "centroid initializations and values of K.\n",
    "\n",
    "Note that each \"point\" is a user as represented by 1000 words, and that\n",
    "word-frequency distributions are generally heavy-tailed power-laws\n",
    "(often called Zipf distributions), and are very rare in the larger class\n",
    "of discrete, random distributions. For each user you will have to normalize\n",
    "by its \"TOTAL\" column. Try several parameterizations and initializations:\n",
    "\n",
    "(A) K=4 uniform random centroid-distributions over the 1000 words\n",
    "(B) K=2 perturbation-centroids, randomly perturbed from the aggregated (user-wide) distribution \n",
    "(C) K=4 perturbation-centroids, randomly perturbed from the aggregated (user-wide) distribution \n",
    "(D) K=4 \"trained\" centroids, determined by the sums across the classes.\n",
    "\n",
    "and iterate until a threshold (try 0.001) is reached.\n",
    "After convergence, print out a summary of the classes present in each cluster.\n",
    "In particular, report the composition as measured by the total\n",
    "portion of each class type (0-3) contained in each cluster,\n",
    "and discuss your findings and any differences in outcomes across parts A-D.\n",
    "\n",
    "Note that you do not have to compute the aggregated distribution or the \n",
    "class-aggregated distributions, which are rows in the auxiliary file:\n",
    "\n",
    "topUsers_Apr-Jul_2014_1000-words_summaries.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of unique products and product frequency can be solved together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "import sys\n",
    "item_inventory = {}\n",
    "\n",
    "for line in sys.stdin:\n",
    "    for item in line.rstrip('\\n').split():\n",
    "        item_inventory[item] = item_inventory.get(item, 0) + 1\n",
    "            \n",
    "for item, inventory in item_inventory.iteritems():\n",
    "    print \"{}\\t{}\".format(item, inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "import sys\n",
    "\n",
    "unique_item_count = 0\n",
    "current_item_count = 0\n",
    "current_item = \"\"\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line = line.rstrip('\\n').split()\n",
    "    if current_item == line[0]:\n",
    "        # If same item, add to count\n",
    "        current_item_count += int(line[1])\n",
    "    else:\n",
    "        # If new item, print, increment unique, restart count\n",
    "        if unique_item_count > 0:\n",
    "            print current_item, current_item_count\n",
    "        unique_item_count += 1\n",
    "        current_item_count = int(line[1])\n",
    "        current_item = line[0]\n",
    "        \n",
    "# Print final row of counts\n",
    "print current_item, current_item_count\n",
    "\n",
    "# Finally, print the number of unique items (will be on last row of reducer output)\n",
    "print unique_item_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use chmod for permissions\n",
    "!chmod a+x mapper.py\n",
    "!chmod a+x reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/09/22 16:31:53 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "mkdir: `W261/In/HW3': File exists\n",
      "15/09/22 16:31:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "put: `W261/In/HW3/ProductPurchaseData.txt': File exists\n"
     ]
    }
   ],
   "source": [
    "# Move files and make directory\n",
    "!hadoop fs -mkdir ./W261/In/HW3\n",
    "!hdfs dfs -put ./ProductPurchaseData.txt ./W261/In/HW3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/09/22 16:32:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "15/09/22 16:32:06 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "15/09/22 16:32:06 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "15/09/22 16:32:06 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "15/09/22 16:32:07 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "15/09/22 16:32:08 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "15/09/22 16:32:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1814222973_0001\n",
      "15/09/22 16:32:09 INFO mapred.LocalDistributedCacheManager: Localized file:/Users/cjllop/Code/MIDS/W261/HW/W3/mapper.py as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1442953928736/mapper.py\n",
      "15/09/22 16:32:09 INFO mapred.LocalDistributedCacheManager: Localized file:/Users/cjllop/Code/MIDS/W261/HW/W3/reducer.py as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1442953928737/reducer.py\n",
      "15/09/22 16:32:09 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "15/09/22 16:32:09 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "15/09/22 16:32:09 INFO mapreduce.Job: Running job: job_local1814222973_0001\n",
      "15/09/22 16:32:09 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "15/09/22 16:32:09 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "15/09/22 16:32:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1814222973_0001_m_000000_0\n",
      "15/09/22 16:32:10 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\n",
      "15/09/22 16:32:10 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\n",
      "15/09/22 16:32:10 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/cjllop/W261/In/HW3/ProductPurchaseData.txt:0+3458517\n",
      "15/09/22 16:32:10 INFO mapred.MapTask: numReduceTasks: 1\n",
      "15/09/22 16:32:10 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "15/09/22 16:32:10 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "15/09/22 16:32:10 INFO mapred.MapTask: soft limit at 83886080\n",
      "15/09/22 16:32:10 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "15/09/22 16:32:10 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "15/09/22 16:32:10 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "15/09/22 16:32:10 INFO streaming.PipeMapRed: PipeMapRed exec [/Users/cjllop/Code/MIDS/W261/HW/W3/././mapper.py]\n",
      "15/09/22 16:32:10 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "15/09/22 16:32:10 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "15/09/22 16:32:10 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "15/09/22 16:32:10 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "15/09/22 16:32:10 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "15/09/22 16:32:10 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "15/09/22 16:32:10 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "15/09/22 16:32:10 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "15/09/22 16:32:10 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "15/09/22 16:32:10 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "15/09/22 16:32:10 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "15/09/22 16:32:10 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "15/09/22 16:32:10 INFO mapreduce.Job: Job job_local1814222973_0001 running in uber mode : false\n",
      "15/09/22 16:32:10 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "15/09/22 16:32:11 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:1=1/1 [rec/s] out:0=0/1 [rec/s]\n",
      "15/09/22 16:32:11 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:10=10/1 [rec/s] out:0=0/1 [rec/s]\n",
      "15/09/22 16:32:11 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:100=100/1 [rec/s] out:0=0/1 [rec/s]\n",
      "15/09/22 16:32:11 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:1000=1000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "15/09/22 16:32:12 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:10000=10000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "15/09/22 16:32:12 INFO streaming.PipeMapRed: Records R/W=31101/1\n",
      "15/09/22 16:32:12 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "15/09/22 16:32:12 INFO streaming.PipeMapRed: mapRedFinished\n",
      "15/09/22 16:32:12 INFO mapred.LocalJobRunner: \n",
      "15/09/22 16:32:12 INFO mapred.MapTask: Starting flush of map output\n",
      "15/09/22 16:32:12 INFO mapred.MapTask: Spilling map output\n",
      "15/09/22 16:32:12 INFO mapred.MapTask: bufstart = 0; bufend = 142658; bufvoid = 104857600\n",
      "15/09/22 16:32:12 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26164032(104656128); length = 50365/6553600\n",
      "15/09/22 16:32:12 INFO mapred.MapTask: Finished spill 0\n",
      "15/09/22 16:32:12 INFO mapred.Task: Task:attempt_local1814222973_0001_m_000000_0 is done. And is in the process of committing\n",
      "15/09/22 16:32:12 INFO mapred.LocalJobRunner: Records R/W=31101/1\n",
      "15/09/22 16:32:12 INFO mapred.Task: Task 'attempt_local1814222973_0001_m_000000_0' done.\n",
      "15/09/22 16:32:12 INFO mapred.LocalJobRunner: Finishing task: attempt_local1814222973_0001_m_000000_0\n",
      "15/09/22 16:32:12 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "15/09/22 16:32:12 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "15/09/22 16:32:12 INFO mapred.LocalJobRunner: Starting task: attempt_local1814222973_0001_r_000000_0\n",
      "15/09/22 16:32:12 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\n",
      "15/09/22 16:32:12 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\n",
      "15/09/22 16:32:12 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@16a99013\n",
      "15/09/22 16:32:12 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=371130368, maxSingleShuffleLimit=92782592, mergeThreshold=244946048, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "15/09/22 16:32:12 INFO reduce.EventFetcher: attempt_local1814222973_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "15/09/22 16:32:13 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1814222973_0001_m_000000_0 decomp: 167844 len: 167848 to MEMORY\n",
      "15/09/22 16:32:13 INFO reduce.InMemoryMapOutput: Read 167844 bytes from map-output for attempt_local1814222973_0001_m_000000_0\n",
      "15/09/22 16:32:13 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 167844, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->167844\n",
      "15/09/22 16:32:13 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "15/09/22 16:32:13 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "15/09/22 16:32:13 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "15/09/22 16:32:13 INFO mapred.Merger: Merging 1 sorted segments\n",
      "15/09/22 16:32:13 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 167833 bytes\n",
      "15/09/22 16:32:13 INFO reduce.MergeManagerImpl: Merged 1 segments, 167844 bytes to disk to satisfy reduce memory limit\n",
      "15/09/22 16:32:13 INFO reduce.MergeManagerImpl: Merging 1 files, 167848 bytes from disk\n",
      "15/09/22 16:32:13 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "15/09/22 16:32:13 INFO mapred.Merger: Merging 1 sorted segments\n",
      "15/09/22 16:32:13 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 167833 bytes\n",
      "15/09/22 16:32:13 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "15/09/22 16:32:13 INFO streaming.PipeMapRed: PipeMapRed exec [/Users/cjllop/Code/MIDS/W261/HW/W3/././reducer.py]\n",
      "15/09/22 16:32:13 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "15/09/22 16:32:13 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "15/09/22 16:32:13 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:32:13 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:32:13 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:32:13 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:32:13 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:32:13 INFO streaming.PipeMapRed: Records R/W=11568/1\n",
      "15/09/22 16:32:13 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "15/09/22 16:32:13 INFO streaming.PipeMapRed: mapRedFinished\n",
      "15/09/22 16:32:13 INFO mapred.Task: Task:attempt_local1814222973_0001_r_000000_0 is done. And is in the process of committing\n",
      "15/09/22 16:32:13 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "15/09/22 16:32:13 INFO mapred.Task: Task attempt_local1814222973_0001_r_000000_0 is allowed to commit now\n",
      "15/09/22 16:32:13 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1814222973_0001_r_000000_0' to hdfs://localhost:9000/user/cjllop/W261/Out/HW3_1_a/_temporary/0/task_local1814222973_0001_r_000000\n",
      "15/09/22 16:32:13 INFO mapred.LocalJobRunner: Records R/W=11568/1 > reduce\n",
      "15/09/22 16:32:13 INFO mapred.Task: Task 'attempt_local1814222973_0001_r_000000_0' done.\n",
      "15/09/22 16:32:13 INFO mapred.LocalJobRunner: Finishing task: attempt_local1814222973_0001_r_000000_0\n",
      "15/09/22 16:32:13 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "15/09/22 16:32:13 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "15/09/22 16:32:13 INFO mapreduce.Job: Job job_local1814222973_0001 completed successfully\n",
      "15/09/22 16:32:13 INFO mapreduce.Job: Counters: 35\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=548034\n",
      "\t\tFILE: Number of bytes written=1258534\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=6917034\n",
      "\t\tHDFS: Number of bytes written=155257\n",
      "\t\tHDFS: Number of read operations=13\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=4\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=31101\n",
      "\t\tMap output records=12592\n",
      "\t\tMap output bytes=142658\n",
      "\t\tMap output materialized bytes=167848\n",
      "\t\tInput split bytes=121\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=12592\n",
      "\t\tReduce shuffle bytes=167848\n",
      "\t\tReduce input records=12592\n",
      "\t\tReduce output records=12593\n",
      "\t\tSpilled Records=25184\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=6\n",
      "\t\tTotal committed heap usage (bytes)=397893632\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3458517\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=155257\n",
      "15/09/22 16:32:13 INFO streaming.StreamJob: Output directory: ./W261/Out/HW3_1_a\n"
     ]
    }
   ],
   "source": [
    "# HW3.1_a: Execute a job using Hadoop Streaming to generate 10,000 random integers and sort them.\n",
    "def HW3_1a():\n",
    "    !hadoop jar /usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar \\\n",
    "    -Dmapreduce.job.maps=10 \\\n",
    "    -Dmapreduce.job.reduces=1 \\\n",
    "    -files ./mapper.py,./reducer.py \\\n",
    "    -mapper ./mapper.py  \\\n",
    "    -reducer ./reducer.py \\\n",
    "    -input ./W261/In/HW3/ProductPurchaseData.txt -output ./W261/Out/HW3_1_a    \n",
    "    \n",
    "HW3_1a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 results in the reducer output are:\n",
      "15/09/22 16:32:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "DAI11153 8\t\n",
      "DAI11223 155\t\n",
      "DAI11238 3\t\n",
      "DAI11257 1\t\n",
      "DAI11261 6\t\n",
      "cat: Unable to write to output stream.\n",
      "\n",
      "The total number of unique items is:\n",
      "15/09/22 16:32:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "12592\t\n"
     ]
    }
   ],
   "source": [
    "print \"The first 5 results in the reducer output are:\"\n",
    "!hadoop fs -cat ./W261/Out/HW3_1_a/part-00000 | head -n5\n",
    "\n",
    "print\n",
    "print \"The total number of unique items is:\"\n",
    "!hadoop fs -cat ./W261/Out/HW3_1_a/part-00000 | tail -n1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Largest basket and frequency of basket counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "import sys\n",
    "\n",
    "basket_inventory = {}\n",
    "\n",
    "for basket in sys.stdin:\n",
    "#    for basket in line:\n",
    "    basket = basket.rstrip('\\n')\n",
    "    basket_inventory[basket] = basket_inventory.get(basket, 0) + 1\n",
    "            \n",
    "# Note - this code assumes we can fit the ENTIRE document in memory. This isnt' best practice.\n",
    "#   I should really updated this code to check memory and emit whenever memory hits a certain point.\n",
    "for basket, inventory in basket_inventory.iteritems():\n",
    "    print \"{}\\t{}\".format(basket, inventory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "import sys\n",
    "\n",
    "unique_basket_count = 0\n",
    "current_basket_count = 0\n",
    "current_basket = \"\"\n",
    "largest_basket = []\n",
    "largest_basket_size = 0\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line = line.rstrip('\\n').split('\\t')\n",
    "    if current_basket == line[0]:\n",
    "        # If same item, add to count\n",
    "        current_basket_count += int(line[1])\n",
    "    else:\n",
    "        # If new item, print, increment unique, restart count\n",
    "        if unique_basket_count > 0:\n",
    "            print current_basket.rstrip('\\n'), current_basket_count\n",
    "        unique_basket_count += 1\n",
    "        current_basket_count = int(line[1])\n",
    "        current_basket = line[0]\n",
    "        \n",
    "    # Track the maximum basket size\n",
    "    if len(current_basket.split()) > largest_basket_size:\n",
    "        largest_basket_size = len(current_basket.split())\n",
    "        largest_basket = [current_basket]\n",
    "    elif len(current_basket.split()) == largest_basket_size:\n",
    "        largest_basket.append(current_basket)\n",
    "        \n",
    "print current_basket.rstrip('\\n'), current_basket_count\n",
    "print \"The largest basket(s) have {} items. There are {} such baskets: {}\".format(\n",
    "    largest_basket_size, len(largest_basket), largest_basket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/09/22 16:33:00 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "15/09/22 16:33:01 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "15/09/22 16:33:01 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "15/09/22 16:33:01 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "15/09/22 16:33:01 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "15/09/22 16:33:02 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "15/09/22 16:33:02 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1607662248_0001\n",
      "15/09/22 16:33:02 INFO mapred.LocalDistributedCacheManager: Localized file:/Users/cjllop/Code/MIDS/W261/HW/W3/mapper.py as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1442953982366/mapper.py\n",
      "15/09/22 16:33:02 INFO mapred.LocalDistributedCacheManager: Localized file:/Users/cjllop/Code/MIDS/W261/HW/W3/reducer.py as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1442953982367/reducer.py\n",
      "15/09/22 16:33:03 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "15/09/22 16:33:03 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "15/09/22 16:33:03 INFO mapreduce.Job: Running job: job_local1607662248_0001\n",
      "15/09/22 16:33:03 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "15/09/22 16:33:03 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "15/09/22 16:33:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1607662248_0001_m_000000_0\n",
      "15/09/22 16:33:03 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\n",
      "15/09/22 16:33:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\n",
      "15/09/22 16:33:03 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/cjllop/W261/In/HW3/ProductPurchaseData.txt:0+3458517\n",
      "15/09/22 16:33:03 INFO mapred.MapTask: numReduceTasks: 1\n",
      "15/09/22 16:33:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "15/09/22 16:33:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "15/09/22 16:33:03 INFO mapred.MapTask: soft limit at 83886080\n",
      "15/09/22 16:33:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "15/09/22 16:33:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "15/09/22 16:33:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "15/09/22 16:33:03 INFO streaming.PipeMapRed: PipeMapRed exec [/Users/cjllop/Code/MIDS/W261/HW/W3/././mapper.py]\n",
      "15/09/22 16:33:03 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "15/09/22 16:33:03 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "15/09/22 16:33:03 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "15/09/22 16:33:03 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "15/09/22 16:33:03 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "15/09/22 16:33:03 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "15/09/22 16:33:03 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "15/09/22 16:33:03 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "15/09/22 16:33:03 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "15/09/22 16:33:03 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "15/09/22 16:33:03 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "15/09/22 16:33:03 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "15/09/22 16:33:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:33:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:33:03 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:33:03 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:33:03 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:33:03 INFO streaming.PipeMapRed: Records R/W=31101/1\n",
      "15/09/22 16:33:03 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "15/09/22 16:33:03 INFO streaming.PipeMapRed: mapRedFinished\n",
      "15/09/22 16:33:03 INFO mapred.LocalJobRunner: \n",
      "15/09/22 16:33:03 INFO mapred.MapTask: Starting flush of map output\n",
      "15/09/22 16:33:03 INFO mapred.MapTask: Spilling map output\n",
      "15/09/22 16:33:03 INFO mapred.MapTask: bufstart = 0; bufend = 3501924; bufvoid = 104857600\n",
      "15/09/22 16:33:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26091612(104366448); length = 122785/6553600\n",
      "15/09/22 16:33:04 INFO mapreduce.Job: Job job_local1607662248_0001 running in uber mode : false\n",
      "15/09/22 16:33:04 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "15/09/22 16:33:04 INFO mapred.MapTask: Finished spill 0\n",
      "15/09/22 16:33:04 INFO mapred.Task: Task:attempt_local1607662248_0001_m_000000_0 is done. And is in the process of committing\n",
      "15/09/22 16:33:04 INFO mapred.LocalJobRunner: Records R/W=31101/1\n",
      "15/09/22 16:33:04 INFO mapred.Task: Task 'attempt_local1607662248_0001_m_000000_0' done.\n",
      "15/09/22 16:33:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1607662248_0001_m_000000_0\n",
      "15/09/22 16:33:04 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "15/09/22 16:33:04 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "15/09/22 16:33:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1607662248_0001_r_000000_0\n",
      "15/09/22 16:33:04 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\n",
      "15/09/22 16:33:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\n",
      "15/09/22 16:33:04 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4f88f506\n",
      "15/09/22 16:33:04 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=371130368, maxSingleShuffleLimit=92782592, mergeThreshold=244946048, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "15/09/22 16:33:04 INFO reduce.EventFetcher: attempt_local1607662248_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "15/09/22 16:33:04 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1607662248_0001_m_000000_0 decomp: 3572667 len: 3572671 to MEMORY\n",
      "15/09/22 16:33:04 INFO reduce.InMemoryMapOutput: Read 3572667 bytes from map-output for attempt_local1607662248_0001_m_000000_0\n",
      "15/09/22 16:33:04 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3572667, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3572667\n",
      "15/09/22 16:33:04 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "15/09/22 16:33:04 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "15/09/22 16:33:04 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "15/09/22 16:33:04 INFO mapred.Merger: Merging 1 sorted segments\n",
      "15/09/22 16:33:04 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 3572610 bytes\n",
      "15/09/22 16:33:04 INFO reduce.MergeManagerImpl: Merged 1 segments, 3572667 bytes to disk to satisfy reduce memory limit\n",
      "15/09/22 16:33:04 INFO reduce.MergeManagerImpl: Merging 1 files, 3572671 bytes from disk\n",
      "15/09/22 16:33:04 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "15/09/22 16:33:04 INFO mapred.Merger: Merging 1 sorted segments\n",
      "15/09/22 16:33:04 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 3572610 bytes\n",
      "15/09/22 16:33:04 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "15/09/22 16:33:04 INFO streaming.PipeMapRed: PipeMapRed exec [/Users/cjllop/Code/MIDS/W261/HW/W3/././reducer.py]\n",
      "15/09/22 16:33:04 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "15/09/22 16:33:04 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "15/09/22 16:33:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:33:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:33:04 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:33:04 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:33:04 INFO streaming.PipeMapRed: Records R/W=1186/1\n",
      "15/09/22 16:33:04 INFO streaming.PipeMapRed: R/W/S=10000/8600/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:33:04 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "15/09/22 16:33:04 INFO streaming.PipeMapRed: mapRedFinished\n",
      "15/09/22 16:33:05 INFO mapred.Task: Task:attempt_local1607662248_0001_r_000000_0 is done. And is in the process of committing\n",
      "15/09/22 16:33:05 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "15/09/22 16:33:05 INFO mapred.Task: Task attempt_local1607662248_0001_r_000000_0 is allowed to commit now\n",
      "15/09/22 16:33:05 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1607662248_0001_r_000000_0' to hdfs://localhost:9000/user/cjllop/W261/Out/HW3_1_b/_temporary/0/task_local1607662248_0001_r_000000\n",
      "15/09/22 16:33:05 INFO mapred.LocalJobRunner: Records R/W=1186/1 > reduce\n",
      "15/09/22 16:33:05 INFO mapred.Task: Task 'attempt_local1607662248_0001_r_000000_0' done.\n",
      "15/09/22 16:33:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1607662248_0001_r_000000_0\n",
      "15/09/22 16:33:05 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "15/09/22 16:33:05 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "15/09/22 16:33:06 INFO mapreduce.Job: Job job_local1607662248_0001 completed successfully\n",
      "15/09/22 16:33:06 INFO mapreduce.Job: Counters: 35\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=7358968\n",
      "\t\tFILE: Number of bytes written=11474303\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=6917034\n",
      "\t\tHDFS: Number of bytes written=3524013\n",
      "\t\tHDFS: Number of read operations=13\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=4\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=31101\n",
      "\t\tMap output records=30697\n",
      "\t\tMap output bytes=3501924\n",
      "\t\tMap output materialized bytes=3572671\n",
      "\t\tInput split bytes=121\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=30697\n",
      "\t\tReduce shuffle bytes=3572671\n",
      "\t\tReduce input records=30697\n",
      "\t\tReduce output records=30698\n",
      "\t\tSpilled Records=61394\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=6\n",
      "\t\tTotal committed heap usage (bytes)=397893632\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3458517\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=3524013\n",
      "15/09/22 16:33:06 INFO streaming.StreamJob: Output directory: ./W261/Out/HW3_1_b\n"
     ]
    }
   ],
   "source": [
    "# HW3.1_b: Execute a job using Hadoop Streaming to generate 10,000 random integers and sort them.\n",
    "def HW3_1b():\n",
    "    !hadoop jar /usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar \\\n",
    "    -Dmapreduce.job.maps=10 \\\n",
    "    -Dmapreduce.job.reduces=1 \\\n",
    "    -files ./mapper.py,./reducer.py \\\n",
    "    -mapper ./mapper.py  \\\n",
    "    -reducer ./reducer.py \\\n",
    "    -input ./W261/In/HW3/ProductPurchaseData.txt -output ./W261/Out/HW3_1_b    \n",
    "    \n",
    "HW3_1b()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 results in the reducer output are:\n",
      "15/09/22 16:33:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "DAI11223 ELE54102 SNA56249 SNA30755 FRO80039 SNA53220  1\t\n",
      "DAI11238 SNA82274 SNA96466 GRO88324 SNA43409 FRO35729 GRO83463 GRO30912 ELE34234 ELE26753 ELE45560 ELE99887 ELE23393 SNA31446 SNA40784 GRO71621  1\t\n",
      "DAI11290 DAI37288 ELE55848 ELE32164 DAI43747 GRO17794 DAI43223 ELE20196 SNA26019 ELE62598 SNA42528 DAI92600 DAI42083 GRO59710 FRO56832 ELE75000  1\t\n",
      "DAI11290 DAI55148 DAI62779 GRO17794 SNA70824 SNA32151 FRO75586  1\t\n",
      "DAI11555 ELE66810 GRO43642 ELE66600 FRO91992  1\t\n",
      "cat: Unable to write to output stream.\n",
      "\n",
      "Printing largest baskets....\n",
      "15/09/22 16:33:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "The largest basket(s) have 37 items. There are 2 such baskets: ['FRO31317 DAI94514 FRO49726 FRO83352 FRO61354 GRO35122 GRO82670 GRO63683 GRO73461 GRO15017 GRO61133 FRO78087 SNA26649 GRO71615 ELE28573 FRO47962 GRO59710 ELE12516 GRO39357 SNA56073 GRO87006 ELE25172 GRO93333 ELE20847 FRO75586 FRO16142 FRO94733 FRO32801 SNA11790 FRO45082 ELE66600 DAI43223 GRO50832 FRO40251 GRO38636 GRO38814 FRO33870 ', 'GRO21487 FRO85978 DAI89320 SNA53220 SNA55762 GRO46854 ELE38511 SNA66583 FRO79579 FRO92469 FRO40251 GRO97448 DAI35347 FRO31317 FRO87622 SNA42518 ELE53126 ELE17451 GRO32086 ELE30327 DAI58206 DAI38969 ELE16038 DAI75645 DAI55148 GRO94173 ELE43952 FRO69613 GRO81647 GRO73461 FRO24098 ELE96667 GRO88324 GRO82670 GRO12815 SNA37475 ELE24369 ']\t\n"
     ]
    }
   ],
   "source": [
    "print \"The first 5 results in the reducer output are:\"\n",
    "!hadoop fs -cat ./W261/Out/HW3_1_b/part-00000 | head -n5\n",
    "\n",
    "print\n",
    "print \"Printing largest baskets....\"\n",
    "!hadoop fs -cat ./W261/Out/HW3_1_b/part-00000 | tail -n1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:silver\"><b>HW3.2.</b> (Computationally prohibitive but then again Hadoop can handle this)</span>\n",
    "\n",
    "<span style=\"color:silver\">Note: for this part the writeup will require a specific rule ordering but the program need not sort the output.</span>\n",
    "\n",
    "<span style=\"color:silver\">List the top 5 rules with corresponding confidence scores in decreasing order of confidence score \n",
    "for frequent (100>count) itemsets of size 2. </span>\n",
    "<span style=\"color:silver\">A rule is of the form: </span>\n",
    "\n",
    "<span style=\"color:silver\">(item1) ⇒ item2.</span>\n",
    "\n",
    "<span style=\"color:silver\">Fix the ordering of the rule lexicographically (left to right), \n",
    "and break ties in confidence (between rules, if any exist) \n",
    "by taking the first ones in lexicographically increasing order. \n",
    "Use Hadoop MapReduce to complete this part of the assignment; \n",
    "use a single mapper and single reducer; use a combiner if you think it will help and justify. </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"><b>Answer:</b></span>\n",
    "I will solve this using the Apriori algorithm. To do so, we must first tabulate the counts for each item. Then, when checking item pairs, we first will make sure that each item is 'frequent' before checking to see if the item pair is 'frequent'. If either of the two items in the proposed pair is not frequent, we can skip checking to see if the pair itself is frequent.\n",
    "\n",
    "I will do this using inverted ordering. The mapper/combiner will output two sorts of records:\n",
    "\n",
    "The first type of record will automatically sort to the top and will allow us to calculate single-item frequency before processing pairs:\n",
    "\n",
    "\\* ITEM_ID COUNT\n",
    "\n",
    "The second type of record will count pairs. Because of the inverted ordering, we can be assured we can calculate the single-term frequency before processing the term pairs:\n",
    "\n",
    "*ITEM_ID ITEM_ID COUNT\n",
    "\n",
    "\n",
    "I will use the \"pairs\" approach, as explained in the code comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "import sys\n",
    "\n",
    "# Formula is: I -> J = (I U J) / I\n",
    "\n",
    "# Pairs Approach | Note, I'm traveling to see a sick family member this weekend. While\n",
    "# stipes is faster and perhaps a better approach, I am making the design decision that, in \n",
    "# my case, time of the programmer is the resource that we need to take into account. You can \n",
    "# liken this to a business situation where a project cannot afford programing hours, but can\n",
    "# have a longer runtime :). In future weeks, I'll make different decisions to experiment\n",
    "# with stripes.\n",
    "\n",
    "# To gain some efficiecny back, I'll write a quick combiner to help make things better.\n",
    "# In this case, there is no way the combiner will hurt things. I have to write code similar \n",
    "# to the combiner for the reducer anyways, so I'll just let Hadoop decide if it has spare\n",
    "# bandwidth to run the combiner. Remember: Hadoop doesn't guarantee it will run the combiner\n",
    "# if it doesn't make sense to.\n",
    "\n",
    "basket_inventory = {}\n",
    "        \n",
    "for basket in sys.stdin:\n",
    "    # Get unique items in basket\n",
    "    basket = list(set(basket.rstrip('\\n').split()))\n",
    "\n",
    "    # Output a single record for each item so that we can use order inversion in our\n",
    "    # reduce side frequency count.\n",
    "    for item1 in basket:\n",
    "        for item2 in basket:\n",
    "            if item1 == item2:\n",
    "                print \"* {}\\t1\".format(item1)\n",
    "            else:\n",
    "                print \"{} {}\\t1\".format(item1, item2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting combiner.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile combiner.py\n",
    "#!/usr/bin/python\n",
    "import sys\n",
    "\n",
    "#itempairs = [\"* 55\\t1\",\"* 55\\t1\",\"* 66\\t1\",\"23 45\\t1\",\"23 45\\t1\",\"23 95\\t1\"]\n",
    "currentpair = \"\"\n",
    "currentcount = 0\n",
    "\n",
    "for itempair in sys.stdin:\n",
    "#for itempair in itempairs:\n",
    "    itempair = itempair.rstrip('\\n')\n",
    "    # If multiple of one key in a row, sum\n",
    "    if itempair.split('\\t')[0] == currentpair:\n",
    "        currentcount += int(itempair.split('\\t')[1])\n",
    "    else:\n",
    "        # Otherwise, print and reset counters. Note - a combiner must print in the same format\n",
    "        # as a mapper.\n",
    "        if currentcount > 0:\n",
    "            print \"{}\\t{}\".format(currentpair, currentcount)\n",
    "        currentpair = itempair.split('\\t')[0]\n",
    "        currentcount = int(itempair.split('\\t')[1])\n",
    "print \"{}\\t{}\".format(currentpair, currentcount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "import sys\n",
    "\n",
    "currentpair = \"\"\n",
    "currentcount = 0\n",
    "itemlist_freq = {}\n",
    "itempair_freq = {}\n",
    "frequent_cutoff = 100\n",
    "\n",
    "#itempairs = [\"* 55\\t1\",\"* 55\\t3\",\"* 45\\t51\",\"* 66\\t1\",\"23 95\\t1\",\"55 45\\t1\",\"55 45\\t1\"]\n",
    "\n",
    "#for itempair in itempairs:\n",
    "for itempair in sys.stdin:\n",
    "    itempair = itempair.rstrip('\\n')\n",
    "    itempair, count = itempair.split('\\t')\n",
    "    firstitem, seconditem = itempair.split(' ')\n",
    "    \n",
    "    # For all sorts of records, we are not assured that the combiner fully combined\n",
    "    # things. As such, we make sure the reducer finishes combining.\n",
    "    # If we have a repeated key, sum the count\n",
    "    if itempair == currentpair:\n",
    "        currentcount += int(count)\n",
    "    else:\n",
    "        # Otherwise, post process\n",
    "        if currentcount > 0:\n",
    "            # For \"*\" records, store into dictionary to use later\n",
    "            if currentpair.split()[0] == \"*\":\n",
    "                itemlist_freq[currentpair.split()[1]] = currentcount\n",
    "#                    print \"{}\\t{}\".format(currentpair, currentcount)\n",
    "            elif firstitem != \"*\":\n",
    "            # For pairs, first see if components pass the min value (100)\n",
    "            # Note - this step isn't technically needed since we already have the\n",
    "            # pair count, however, we implement it in the spirit of the Apriori Alg.\n",
    "                if itemlist_freq.get(currentpair.split()[0], 0) > frequent_cutoff and itemlist_freq.get(\n",
    "                    currentpair.split()[1], 0) > frequent_cutoff:\n",
    "                    # If both components pass, check to see if the full count passes\n",
    "                    if currentcount > frequent_cutoff:\n",
    "                        # In this case, we can calculate confidence score and output\n",
    "                        print \"{} => {} = {}\".format(currentpair.split()[0], currentpair.split(\n",
    "                            )[1], float(currentcount)/itemlist_freq[currentpair.split()[0]])\n",
    "        currentpair = itempair\n",
    "        currentcount = int(count)\n",
    "\n",
    "# Because of our loop structure, we'll need to check then output one last score\n",
    "if itemlist_freq.get(currentpair.split()[0], 0) > frequent_cutoff and itemlist_freq.get(\n",
    "    currentpair.split()[1], 0) > frequent_cutoff:\n",
    "    # If both components pass, check to see if the full count passes\n",
    "    if currentcount > frequent_cutoff:\n",
    "        # In this case, we can calculate confidence score and output\n",
    "        print \"{} => {} = {}\".format(currentpair.split()[0], currentpair.split(\n",
    "            )[1], float(currentcount)/itemlist_freq[currentpair.split()[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/09/22 16:34:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "15/09/22 16:34:12 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "15/09/22 16:34:12 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "15/09/22 16:34:12 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "15/09/22 16:34:12 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "15/09/22 16:34:12 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "15/09/22 16:34:13 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1521152290_0001\n",
      "15/09/22 16:34:13 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "15/09/22 16:34:13 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "15/09/22 16:34:13 INFO mapreduce.Job: Running job: job_local1521152290_0001\n",
      "15/09/22 16:34:13 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "15/09/22 16:34:13 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "15/09/22 16:34:13 INFO mapred.LocalJobRunner: Starting task: attempt_local1521152290_0001_m_000000_0\n",
      "15/09/22 16:34:13 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\n",
      "15/09/22 16:34:13 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\n",
      "15/09/22 16:34:13 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/cjllop/W261/In/HW3/ProductPurchaseData.txt:0+3458517\n",
      "15/09/22 16:34:13 INFO mapred.MapTask: numReduceTasks: 1\n",
      "15/09/22 16:34:13 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "15/09/22 16:34:13 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "15/09/22 16:34:13 INFO mapred.MapTask: soft limit at 83886080\n",
      "15/09/22 16:34:13 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "15/09/22 16:34:13 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "15/09/22 16:34:13 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "15/09/22 16:34:13 INFO streaming.PipeMapRed: PipeMapRed exec [/Users/cjllop/Code/MIDS/W261/HW/W3/././mapper.py]\n",
      "15/09/22 16:34:13 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "15/09/22 16:34:13 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "15/09/22 16:34:13 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "15/09/22 16:34:13 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "15/09/22 16:34:13 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "15/09/22 16:34:13 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "15/09/22 16:34:13 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "15/09/22 16:34:13 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "15/09/22 16:34:13 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "15/09/22 16:34:13 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "15/09/22 16:34:13 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "15/09/22 16:34:13 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "15/09/22 16:34:13 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:13 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:13 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:13 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:13 INFO streaming.PipeMapRed: Records R/W=1216/1\n",
      "15/09/22 16:34:14 INFO mapreduce.Job: Job job_local1521152290_0001 running in uber mode : false\n",
      "15/09/22 16:34:14 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "15/09/22 16:34:16 INFO streaming.PipeMapRed: R/W/S=10000/1830427/0 in:5000=10000/2 [rec/s] out:915213=1830427/2 [rec/s]\n",
      "15/09/22 16:34:16 INFO mapred.MapTask: Spilling map output\n",
      "15/09/22 16:34:16 INFO mapred.MapTask: bufstart = 0; bufend = 46124305; bufvoid = 104857600\n",
      "15/09/22 16:34:16 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 16773960(67095840); length = 9440437/6553600\n",
      "15/09/22 16:34:16 INFO mapred.MapTask: (EQUATOR) 55711281 kvi 13927816(55711264)\n",
      "15/09/22 16:34:19 INFO mapred.LocalJobRunner: Records R/W=1216/1 > map\n",
      "15/09/22 16:34:19 INFO streaming.PipeMapRed: PipeMapRed exec [/Users/cjllop/Code/MIDS/W261/HW/W3/././combiner.py]\n",
      "15/09/22 16:34:19 INFO Configuration.deprecation: mapred.skip.map.auto.incr.proc.count is deprecated. Instead, use mapreduce.map.skip.proc-count.auto-incr\n",
      "15/09/22 16:34:20 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:20 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:20 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:20 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:20 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:20 INFO streaming.PipeMapRed: Records R/W=40329/1\n",
      "15/09/22 16:34:20 INFO mapreduce.Job:  map 38% reduce 0%\n",
      "15/09/22 16:34:20 INFO streaming.PipeMapRed: R/W/S=100000/3700/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:20 INFO streaming.PipeMapRed: R/W/S=200000/24663/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:20 INFO streaming.PipeMapRed: R/W/S=300000/65551/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:21 INFO streaming.PipeMapRed: R/W/S=400000/99882/0 in:400000=400000/1 [rec/s] out:99882=99882/1 [rec/s]\n",
      "15/09/22 16:34:21 INFO streaming.PipeMapRed: R/W/S=500000/131749/0 in:500000=500000/1 [rec/s] out:131749=131749/1 [rec/s]\n",
      "15/09/22 16:34:21 INFO streaming.PipeMapRed: R/W/S=600000/160327/0 in:600000=600000/1 [rec/s] out:160327=160327/1 [rec/s]\n",
      "15/09/22 16:34:22 INFO streaming.PipeMapRed: R/W/S=700000/196296/0 in:350000=700000/2 [rec/s] out:98148=196296/2 [rec/s]\n",
      "15/09/22 16:34:22 INFO mapred.LocalJobRunner: Records R/W=40329/1 > map\n",
      "15/09/22 16:34:22 INFO streaming.PipeMapRed: R/W/S=800000/228981/0 in:400000=800000/2 [rec/s] out:114490=228981/2 [rec/s]\n",
      "15/09/22 16:34:22 INFO streaming.PipeMapRed: R/W/S=900000/273962/0 in:450000=900000/2 [rec/s] out:136981=273962/2 [rec/s]\n",
      "15/09/22 16:34:23 INFO streaming.PipeMapRed: R/W/S=1000000/309102/0 in:333333=1000000/3 [rec/s] out:103034=309102/3 [rec/s]\n",
      "15/09/22 16:34:23 INFO streaming.PipeMapRed: R/W/S=1100000/349175/0 in:366666=1100000/3 [rec/s] out:116391=349175/3 [rec/s]\n",
      "15/09/22 16:34:24 INFO streaming.PipeMapRed: R/W/S=1200000/388417/0 in:300000=1200000/4 [rec/s] out:97104=388417/4 [rec/s]\n",
      "15/09/22 16:34:24 INFO streaming.PipeMapRed: R/W/S=1300000/425202/0 in:325000=1300000/4 [rec/s] out:106300=425202/4 [rec/s]\n",
      "15/09/22 16:34:24 INFO streaming.PipeMapRed: R/W/S=1400000/467729/0 in:350000=1400000/4 [rec/s] out:116932=467729/4 [rec/s]\n",
      "15/09/22 16:34:25 INFO streaming.PipeMapRed: R/W/S=1500000/505335/0 in:300000=1500000/5 [rec/s] out:101067=505335/5 [rec/s]\n",
      "15/09/22 16:34:25 INFO mapred.LocalJobRunner: Records R/W=40329/1 > map\n",
      "15/09/22 16:34:25 INFO streaming.PipeMapRed: R/W/S=1600000/542943/0 in:320000=1600000/5 [rec/s] out:108588=542943/5 [rec/s]\n",
      "15/09/22 16:34:25 INFO streaming.PipeMapRed: R/W/S=1700000/580543/0 in:340000=1700000/5 [rec/s] out:116108=580543/5 [rec/s]\n",
      "15/09/22 16:34:26 INFO streaming.PipeMapRed: R/W/S=1800000/613221/0 in:300000=1800000/6 [rec/s] out:102203=613221/6 [rec/s]\n",
      "15/09/22 16:34:26 INFO streaming.PipeMapRed: R/W/S=1900000/643453/0 in:316666=1900000/6 [rec/s] out:107242=643453/6 [rec/s]\n",
      "15/09/22 16:34:26 INFO streaming.PipeMapRed: R/W/S=2000000/686803/0 in:333333=2000000/6 [rec/s] out:114467=686803/6 [rec/s]\n",
      "15/09/22 16:34:27 INFO streaming.PipeMapRed: R/W/S=2100000/729326/0 in:300000=2100000/7 [rec/s] out:104189=729326/7 [rec/s]\n",
      "15/09/22 16:34:27 INFO streaming.PipeMapRed: R/W/S=2200000/769391/0 in:314285=2200000/7 [rec/s] out:109913=769391/7 [rec/s]\n",
      "15/09/22 16:34:27 INFO streaming.PipeMapRed: R/W/S=2300000/807004/0 in:328571=2300000/7 [rec/s] out:115286=807004/7 [rec/s]\n",
      "15/09/22 16:34:28 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "15/09/22 16:34:28 INFO streaming.PipeMapRed: mapRedFinished\n",
      "15/09/22 16:34:28 INFO mapred.MapTask: Finished spill 0\n",
      "15/09/22 16:34:28 INFO mapred.MapTask: (RESET) equator 55711281 kv 13927816(55711264) kvi 11584304(46337216)\n",
      "15/09/22 16:34:28 INFO streaming.PipeMapRed: Records R/W=17860/2945989\n",
      "15/09/22 16:34:28 INFO mapred.LocalJobRunner: Records R/W=17860/2945989 > map\n",
      "15/09/22 16:34:29 INFO mapreduce.Job:  map 40% reduce 0%\n",
      "15/09/22 16:34:30 INFO mapred.MapTask: Spilling map output\n",
      "15/09/22 16:34:30 INFO mapred.MapTask: bufstart = 55711281; bufend = 101780183; bufvoid = 104857600\n",
      "15/09/22 16:34:30 INFO mapred.MapTask: kvstart = 13927816(55711264); kvend = 4473528(17894112); length = 9454289/6553600\n",
      "15/09/22 16:34:30 INFO mapred.MapTask: (EQUATOR) 6509559 kvi 1627384(6509536)\n",
      "15/09/22 16:34:31 INFO mapred.LocalJobRunner: Records R/W=17860/2945989 > map\n",
      "15/09/22 16:34:32 INFO mapreduce.Job:  map 67% reduce 0%\n",
      "15/09/22 16:34:33 INFO streaming.PipeMapRed: PipeMapRed exec [/Users/cjllop/Code/MIDS/W261/HW/W3/././combiner.py]\n",
      "15/09/22 16:34:33 INFO Configuration.deprecation: mapred.skip.reduce.auto.incr.proc.count is deprecated. Instead, use mapreduce.reduce.skip.proc-count.auto-incr\n",
      "15/09/22 16:34:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:33 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:33 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:33 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:33 INFO streaming.PipeMapRed: Records R/W=40329/1\n",
      "15/09/22 16:34:33 INFO streaming.PipeMapRed: R/W/S=100000/3591/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:34 INFO streaming.PipeMapRed: R/W/S=200000/19164/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:34 INFO mapred.LocalJobRunner: Records R/W=40329/1 > map\n",
      "15/09/22 16:34:34 INFO streaming.PipeMapRed: R/W/S=300000/65802/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:34 INFO streaming.PipeMapRed: R/W/S=400000/109155/0 in:400000=400000/1 [rec/s] out:109155=109155/1 [rec/s]\n",
      "15/09/22 16:34:35 INFO streaming.PipeMapRed: R/W/S=500000/144301/0 in:500000=500000/1 [rec/s] out:144301=144301/1 [rec/s]\n",
      "15/09/22 16:34:35 INFO streaming.PipeMapRed: R/W/S=600000/182733/0 in:600000=600000/1 [rec/s] out:182733=182733/1 [rec/s]\n",
      "15/09/22 16:34:35 INFO streaming.PipeMapRed: R/W/S=700000/226087/0 in:350000=700000/2 [rec/s] out:113043=226087/2 [rec/s]\n",
      "15/09/22 16:34:36 INFO streaming.PipeMapRed: R/W/S=800000/266974/0 in:400000=800000/2 [rec/s] out:133487=266974/2 [rec/s]\n",
      "15/09/22 16:34:36 INFO streaming.PipeMapRed: R/W/S=900000/313599/0 in:300000=900000/3 [rec/s] out:104533=313599/3 [rec/s]\n",
      "15/09/22 16:34:36 INFO streaming.PipeMapRed: R/W/S=1000000/356950/0 in:333333=1000000/3 [rec/s] out:118983=356950/3 [rec/s]\n",
      "15/09/22 16:34:37 INFO streaming.PipeMapRed: R/W/S=1100000/403586/0 in:366666=1100000/3 [rec/s] out:134528=403586/3 [rec/s]\n",
      "15/09/22 16:34:37 INFO mapred.LocalJobRunner: Records R/W=40329/1 > map\n",
      "15/09/22 16:34:37 INFO streaming.PipeMapRed: R/W/S=1200000/455150/0 in:300000=1200000/4 [rec/s] out:113787=455150/4 [rec/s]\n",
      "15/09/22 16:34:38 INFO streaming.PipeMapRed: R/W/S=1300000/494846/0 in:325000=1300000/4 [rec/s] out:123718=494874/4 [rec/s]\n",
      "15/09/22 16:34:38 INFO streaming.PipeMapRed: R/W/S=1400000/549237/0 in:350000=1400000/4 [rec/s] out:137309=549237/4 [rec/s]\n",
      "15/09/22 16:34:38 INFO streaming.PipeMapRed: R/W/S=1500000/588484/0 in:300000=1500000/5 [rec/s] out:117696=588484/5 [rec/s]\n",
      "15/09/22 16:34:39 INFO streaming.PipeMapRed: R/W/S=1600000/633477/0 in:320000=1600000/5 [rec/s] out:126695=633477/5 [rec/s]\n",
      "15/09/22 16:34:39 INFO streaming.PipeMapRed: R/W/S=1700000/678461/0 in:283333=1700000/6 [rec/s] out:113076=678461/6 [rec/s]\n",
      "15/09/22 16:34:40 INFO streaming.PipeMapRed: R/W/S=1800000/721810/0 in:300000=1800000/6 [rec/s] out:120301=721810/6 [rec/s]\n",
      "15/09/22 16:34:40 INFO mapred.LocalJobRunner: Records R/W=40329/1 > map\n",
      "15/09/22 16:34:40 INFO streaming.PipeMapRed: R/W/S=1900000/760241/0 in:316666=1900000/6 [rec/s] out:126706=760241/6 [rec/s]\n",
      "15/09/22 16:34:40 INFO streaming.PipeMapRed: R/W/S=2000000/810965/0 in:285714=2000000/7 [rec/s] out:115852=810965/7 [rec/s]\n",
      "15/09/22 16:34:41 INFO streaming.PipeMapRed: R/W/S=2100000/859246/0 in:300000=2100000/7 [rec/s] out:122749=859246/7 [rec/s]\n",
      "15/09/22 16:34:41 INFO streaming.PipeMapRed: R/W/S=2200000/905879/0 in:275000=2200000/8 [rec/s] out:113234=905879/8 [rec/s]\n",
      "15/09/22 16:34:41 INFO streaming.PipeMapRed: R/W/S=2300000/950967/0 in:287500=2300000/8 [rec/s] out:118870=950967/8 [rec/s]\n",
      "15/09/22 16:34:42 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "15/09/22 16:34:42 INFO streaming.PipeMapRed: mapRedFinished\n",
      "15/09/22 16:34:42 INFO mapred.MapTask: Finished spill 1\n",
      "15/09/22 16:34:42 INFO mapred.MapTask: (RESET) equator 6509559 kv 1627384(6509536) kvi 25501436(102005744)\n",
      "15/09/22 16:34:42 INFO streaming.PipeMapRed: Records R/W=31101/5308771\n",
      "15/09/22 16:34:42 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "15/09/22 16:34:42 INFO streaming.PipeMapRed: mapRedFinished\n",
      "15/09/22 16:34:42 INFO mapred.LocalJobRunner: Records R/W=40329/1 > map\n",
      "15/09/22 16:34:42 INFO mapred.MapTask: Starting flush of map output\n",
      "15/09/22 16:34:42 INFO mapred.MapTask: Spilling map output\n",
      "15/09/22 16:34:42 INFO mapred.MapTask: bufstart = 6509559; bufend = 20627585; bufvoid = 104857600\n",
      "15/09/22 16:34:42 INFO mapred.MapTask: kvstart = 1627384(6509536); kvend = 24941124(99764496); length = 2900661/6553600\n",
      "15/09/22 16:34:43 INFO mapred.LocalJobRunner: Records R/W=31101/5308771 > sort\n",
      "15/09/22 16:34:43 INFO streaming.PipeMapRed: PipeMapRed exec [/Users/cjllop/Code/MIDS/W261/HW/W3/././combiner.py]\n",
      "15/09/22 16:34:43 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:43 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:43 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:43 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:43 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:43 INFO streaming.PipeMapRed: Records R/W=30247/1\n",
      "15/09/22 16:34:43 INFO streaming.PipeMapRed: R/W/S=100000/27916/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:44 INFO streaming.PipeMapRed: R/W/S=200000/81114/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:44 INFO streaming.PipeMapRed: R/W/S=300000/135135/0 in:300000=300000/1 [rec/s] out:135135=135135/1 [rec/s]\n",
      "15/09/22 16:34:45 INFO streaming.PipeMapRed: R/W/S=400000/194066/0 in:400000=400000/1 [rec/s] out:194066=194066/1 [rec/s]\n",
      "15/09/22 16:34:45 INFO streaming.PipeMapRed: R/W/S=500000/254651/0 in:500000=500000/1 [rec/s] out:254651=254651/1 [rec/s]\n",
      "15/09/22 16:34:46 INFO streaming.PipeMapRed: R/W/S=600000/307045/0 in:300000=600000/2 [rec/s] out:153522=307045/2 [rec/s]\n",
      "15/09/22 16:34:46 INFO mapred.LocalJobRunner: Records R/W=30247/1 > sort\n",
      "15/09/22 16:34:46 INFO streaming.PipeMapRed: R/W/S=700000/370070/0 in:350000=700000/2 [rec/s] out:185035=370070/2 [rec/s]\n",
      "15/09/22 16:34:46 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "15/09/22 16:34:46 INFO streaming.PipeMapRed: mapRedFinished\n",
      "15/09/22 16:34:46 INFO mapred.MapTask: Finished spill 2\n",
      "15/09/22 16:34:46 INFO mapred.Merger: Merging 3 sorted segments\n",
      "15/09/22 16:34:46 INFO mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 48404963 bytes\n",
      "15/09/22 16:34:46 INFO streaming.PipeMapRed: PipeMapRed exec [/Users/cjllop/Code/MIDS/W261/HW/W3/././combiner.py]\n",
      "15/09/22 16:34:46 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:46 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:46 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:46 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:46 INFO streaming.PipeMapRed: Records R/W=9873/1\n",
      "15/09/22 16:34:46 INFO streaming.PipeMapRed: R/W/S=10000/1227/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:47 INFO streaming.PipeMapRed: R/W/S=100000/72086/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:47 INFO streaming.PipeMapRed: R/W/S=200000/152209/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:48 INFO streaming.PipeMapRed: R/W/S=300000/229794/0 in:300000=300000/1 [rec/s] out:229794=229794/1 [rec/s]\n",
      "15/09/22 16:34:48 INFO streaming.PipeMapRed: R/W/S=400000/313137/0 in:400000=400000/1 [rec/s] out:313137=313137/1 [rec/s]\n",
      "15/09/22 16:34:48 INFO streaming.PipeMapRed: R/W/S=500000/391595/0 in:250000=500000/2 [rec/s] out:195797=391595/2 [rec/s]\n",
      "15/09/22 16:34:49 INFO mapred.LocalJobRunner: Records R/W=9873/1 > sort > \n",
      "15/09/22 16:34:49 INFO mapreduce.Job:  map 76% reduce 0%\n",
      "15/09/22 16:34:49 INFO streaming.PipeMapRed: R/W/S=600000/469210/0 in:300000=600000/2 [rec/s] out:234605=469210/2 [rec/s]\n",
      "15/09/22 16:34:49 INFO streaming.PipeMapRed: R/W/S=700000/547680/0 in:233333=700000/3 [rec/s] out:182560=547680/3 [rec/s]\n",
      "15/09/22 16:34:50 INFO streaming.PipeMapRed: R/W/S=800000/629387/0 in:266666=800000/3 [rec/s] out:209795=629387/3 [rec/s]\n",
      "15/09/22 16:34:50 INFO streaming.PipeMapRed: R/W/S=900000/708690/0 in:225000=900000/4 [rec/s] out:177172=708690/4 [rec/s]\n",
      "15/09/22 16:34:51 INFO streaming.PipeMapRed: R/W/S=1000000/789638/0 in:250000=1000000/4 [rec/s] out:197409=789638/4 [rec/s]\n",
      "15/09/22 16:34:51 INFO streaming.PipeMapRed: R/W/S=1100000/872168/0 in:220000=1100000/5 [rec/s] out:174433=872168/5 [rec/s]\n",
      "15/09/22 16:34:52 INFO streaming.PipeMapRed: R/W/S=1200000/954783/0 in:240000=1200000/5 [rec/s] out:190956=954783/5 [rec/s]\n",
      "15/09/22 16:34:52 INFO mapred.LocalJobRunner: Records R/W=9873/1 > sort > \n",
      "15/09/22 16:34:52 INFO mapreduce.Job:  map 86% reduce 0%\n",
      "15/09/22 16:34:52 INFO streaming.PipeMapRed: R/W/S=1300000/1033374/0 in:260000=1300000/5 [rec/s] out:206677=1033386/5 [rec/s]\n",
      "15/09/22 16:34:52 INFO streaming.PipeMapRed: R/W/S=1400000/1112526/0 in:233333=1400000/6 [rec/s] out:185421=1112526/6 [rec/s]\n",
      "15/09/22 16:34:53 INFO streaming.PipeMapRed: R/W/S=1500000/1196723/0 in:250000=1500000/6 [rec/s] out:199453=1196723/6 [rec/s]\n",
      "15/09/22 16:34:53 INFO streaming.PipeMapRed: R/W/S=1600000/1275978/0 in:228571=1600000/7 [rec/s] out:182282=1275978/7 [rec/s]\n",
      "15/09/22 16:34:54 INFO streaming.PipeMapRed: R/W/S=1700000/1353588/0 in:242857=1700000/7 [rec/s] out:193369=1353588/7 [rec/s]\n",
      "15/09/22 16:34:54 INFO streaming.PipeMapRed: R/W/S=1800000/1438623/0 in:225000=1800000/8 [rec/s] out:179827=1438623/8 [rec/s]\n",
      "15/09/22 16:34:55 INFO streaming.PipeMapRed: R/W/S=1900000/1520419/0 in:237500=1900000/8 [rec/s] out:190052=1520419/8 [rec/s]\n",
      "15/09/22 16:34:55 INFO mapred.LocalJobRunner: Records R/W=9873/1 > sort > \n",
      "15/09/22 16:34:55 INFO mapreduce.Job:  map 96% reduce 0%\n",
      "15/09/22 16:34:55 INFO streaming.PipeMapRed: R/W/S=2000000/1598050/0 in:250000=2000000/8 [rec/s] out:199756=1598050/8 [rec/s]\n",
      "15/09/22 16:34:56 INFO streaming.PipeMapRed: R/W/S=2100000/1678194/0 in:233333=2100000/9 [rec/s] out:186466=1678194/9 [rec/s]\n",
      "15/09/22 16:34:56 INFO streaming.PipeMapRed: R/W/S=2200000/1759901/0 in:244444=2200000/9 [rec/s] out:195544=1759901/9 [rec/s]\n",
      "15/09/22 16:34:56 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "15/09/22 16:34:56 INFO streaming.PipeMapRed: mapRedFinished\n",
      "15/09/22 16:34:56 INFO mapred.Task: Task:attempt_local1521152290_0001_m_000000_0 is done. And is in the process of committing\n",
      "15/09/22 16:34:56 INFO mapred.LocalJobRunner: Records R/W=9873/1 > sort\n",
      "15/09/22 16:34:56 INFO mapred.Task: Task 'attempt_local1521152290_0001_m_000000_0' done.\n",
      "15/09/22 16:34:56 INFO mapred.LocalJobRunner: Finishing task: attempt_local1521152290_0001_m_000000_0\n",
      "15/09/22 16:34:56 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "15/09/22 16:34:56 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "15/09/22 16:34:56 INFO mapred.LocalJobRunner: Starting task: attempt_local1521152290_0001_r_000000_0\n",
      "15/09/22 16:34:56 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\n",
      "15/09/22 16:34:56 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\n",
      "15/09/22 16:34:56 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7846a55e\n",
      "15/09/22 16:34:56 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=371130368, maxSingleShuffleLimit=92782592, mergeThreshold=244946048, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "15/09/22 16:34:56 INFO reduce.EventFetcher: attempt_local1521152290_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "15/09/22 16:34:56 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1521152290_0001_m_000000_0 decomp: 38864678 len: 38864682 to MEMORY\n",
      "15/09/22 16:34:57 INFO reduce.InMemoryMapOutput: Read 38864678 bytes from map-output for attempt_local1521152290_0001_m_000000_0\n",
      "15/09/22 16:34:57 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 38864678, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->38864678\n",
      "15/09/22 16:34:57 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "15/09/22 16:34:57 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "15/09/22 16:34:57 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "15/09/22 16:34:57 INFO mapred.Merger: Merging 1 sorted segments\n",
      "15/09/22 16:34:57 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 38864665 bytes\n",
      "15/09/22 16:34:57 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "15/09/22 16:34:58 INFO reduce.MergeManagerImpl: Merged 1 segments, 38864678 bytes to disk to satisfy reduce memory limit\n",
      "15/09/22 16:34:58 INFO reduce.MergeManagerImpl: Merging 1 files, 38864682 bytes from disk\n",
      "15/09/22 16:34:58 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "15/09/22 16:34:58 INFO mapred.Merger: Merging 1 sorted segments\n",
      "15/09/22 16:34:58 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 38864665 bytes\n",
      "15/09/22 16:34:58 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "15/09/22 16:34:58 INFO streaming.PipeMapRed: PipeMapRed exec [/Users/cjllop/Code/MIDS/W261/HW/W3/././reducer.py]\n",
      "15/09/22 16:34:58 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "15/09/22 16:34:58 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "15/09/22 16:34:58 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:58 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:58 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:58 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:58 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:59 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "15/09/22 16:34:59 INFO streaming.PipeMapRed: R/W/S=200000/0/0 in:200000=200000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "15/09/22 16:34:59 INFO streaming.PipeMapRed: Records R/W=278831/1\n",
      "15/09/22 16:34:59 INFO streaming.PipeMapRed: R/W/S=300000/425/0 in:300000=300000/1 [rec/s] out:425=425/1 [rec/s]\n",
      "15/09/22 16:35:00 INFO streaming.PipeMapRed: R/W/S=400000/425/0 in:200000=400000/2 [rec/s] out:212=425/2 [rec/s]\n",
      "15/09/22 16:35:00 INFO streaming.PipeMapRed: R/W/S=500000/851/0 in:250000=500000/2 [rec/s] out:425=851/2 [rec/s]\n",
      "15/09/22 16:35:01 INFO streaming.PipeMapRed: R/W/S=600000/851/0 in:300000=600000/2 [rec/s] out:425=851/2 [rec/s]\n",
      "15/09/22 16:35:01 INFO streaming.PipeMapRed: R/W/S=700000/851/0 in:233333=700000/3 [rec/s] out:283=851/3 [rec/s]\n",
      "15/09/22 16:35:02 INFO streaming.PipeMapRed: R/W/S=800000/851/0 in:266666=800000/3 [rec/s] out:283=851/3 [rec/s]\n",
      "15/09/22 16:35:02 INFO mapred.LocalJobRunner: Records R/W=278831/1 > reduce\n",
      "15/09/22 16:35:02 INFO streaming.PipeMapRed: R/W/S=900000/1278/0 in:225000=900000/4 [rec/s] out:319=1278/4 [rec/s]\n",
      "15/09/22 16:35:03 INFO streaming.PipeMapRed: R/W/S=1000000/1278/0 in:250000=1000000/4 [rec/s] out:319=1278/4 [rec/s]\n",
      "15/09/22 16:35:03 INFO mapreduce.Job:  map 100% reduce 84%\n",
      "15/09/22 16:35:03 INFO streaming.PipeMapRed: R/W/S=1100000/1278/0 in:220000=1100000/5 [rec/s] out:255=1278/5 [rec/s]\n",
      "15/09/22 16:35:04 INFO streaming.PipeMapRed: R/W/S=1200000/1703/0 in:240000=1200000/5 [rec/s] out:340=1703/5 [rec/s]\n",
      "15/09/22 16:35:04 INFO streaming.PipeMapRed: R/W/S=1300000/1703/0 in:216666=1300000/6 [rec/s] out:283=1703/6 [rec/s]\n",
      "15/09/22 16:35:04 INFO streaming.PipeMapRed: R/W/S=1400000/2132/0 in:233333=1400000/6 [rec/s] out:355=2132/6 [rec/s]\n",
      "15/09/22 16:35:05 INFO streaming.PipeMapRed: R/W/S=1500000/2132/0 in:250000=1500000/6 [rec/s] out:355=2132/6 [rec/s]\n",
      "15/09/22 16:35:05 INFO mapred.LocalJobRunner: Records R/W=278831/1 > reduce\n",
      "15/09/22 16:35:05 INFO streaming.PipeMapRed: R/W/S=1600000/2132/0 in:228571=1600000/7 [rec/s] out:304=2132/7 [rec/s]\n",
      "15/09/22 16:35:06 INFO streaming.PipeMapRed: R/W/S=1700000/2132/0 in:242857=1700000/7 [rec/s] out:304=2132/7 [rec/s]\n",
      "15/09/22 16:35:06 INFO mapreduce.Job:  map 100% reduce 96%\n",
      "15/09/22 16:35:06 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "15/09/22 16:35:06 INFO streaming.PipeMapRed: mapRedFinished\n",
      "15/09/22 16:35:06 INFO mapred.Task: Task:attempt_local1521152290_0001_r_000000_0 is done. And is in the process of committing\n",
      "15/09/22 16:35:06 INFO mapred.LocalJobRunner: Records R/W=278831/1 > reduce\n",
      "15/09/22 16:35:06 INFO mapred.Task: Task attempt_local1521152290_0001_r_000000_0 is allowed to commit now\n",
      "15/09/22 16:35:06 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1521152290_0001_r_000000_0' to hdfs://localhost:9000/user/cjllop/W261/Out/HW3_2/_temporary/0/task_local1521152290_0001_r_000000\n",
      "15/09/22 16:35:06 INFO mapred.LocalJobRunner: Records R/W=278831/1 > reduce\n",
      "15/09/22 16:35:06 INFO mapred.Task: Task 'attempt_local1521152290_0001_r_000000_0' done.\n",
      "15/09/22 16:35:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1521152290_0001_r_000000_0\n",
      "15/09/22 16:35:06 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "15/09/22 16:35:07 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "15/09/22 16:35:07 INFO mapreduce.Job: Job job_local1521152290_0001 completed successfully\n",
      "15/09/22 16:35:07 INFO mapreduce.Job: Counters: 35\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=174749714\n",
      "\t\tFILE: Number of bytes written=214153400\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=6917034\n",
      "\t\tHDFS: Number of bytes written=103286\n",
      "\t\tHDFS: Number of read operations=13\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=4\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=31101\n",
      "\t\tMap output records=5448849\n",
      "\t\tMap output bytes=106311233\n",
      "\t\tMap output materialized bytes=38864682\n",
      "\t\tInput split bytes=121\n",
      "\t\tCombine input records=7652376\n",
      "\t\tCombine output records=3970309\n",
      "\t\tReduce input groups=1766782\n",
      "\t\tReduce shuffle bytes=38864682\n",
      "\t\tReduce input records=1766782\n",
      "\t\tReduce output records=2622\n",
      "\t\tSpilled Records=5737091\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=23\n",
      "\t\tTotal committed heap usage (bytes)=461934592\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3458517\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=103286\n",
      "15/09/22 16:35:07 INFO streaming.StreamJob: Output directory: ./W261/Out/HW3_2\n"
     ]
    }
   ],
   "source": [
    "# HW3.2: Run MapReduce with mapper, reducer, and combiner\n",
    "def HW3_2():\n",
    "    !hadoop jar /usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar \\\n",
    "    -Dmapreduce.job.maps=1 \\\n",
    "    -Dmapreduce.job.reduces=1 \\\n",
    "    -mapper ./mapper.py  \\\n",
    "    -combiner ./combiner.py \\\n",
    "    -reducer ./reducer.py \\\n",
    "    -input ./W261/In/HW3/ProductPurchaseData.txt -output ./W261/Out/HW3_2    \n",
    "HW3_2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 results in the reducer output are:\n",
      "15/09/22 16:35:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "DAI16732 => FRO78087 = 0.566844919786\t\n",
      "DAI18527 => SNA44451 = 0.380597014925\t\n",
      "DAI22177 => DAI31081 = 0.0780577750461\t\n",
      "DAI22177 => DAI62779 = 0.234787953288\t\n",
      "DAI22177 => DAI63921 = 0.0835894283958\t\n",
      "DAI22177 => DAI75645 = 0.0755992624462\t\n",
      "DAI22177 => DAI83733 = 0.0774431468961\t\n",
      "DAI22177 => DAI85309 = 0.105716041795\t\n",
      "DAI22177 => ELE17451 = 0.124769514444\t\n",
      "DAI22177 => ELE26917 = 0.0823601720959\t\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "print \"The first 10 results in the reducer output are:\"\n",
    "!hadoop fs -cat ./W261/Out/HW3_2/part-00000 | head -n10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"><b>Answer:</b></span>\n",
    "We were told we do not need to sort the top list in Hadoop. I will read them from file, after downloading the file from HDFS. The step below shows our final answer:\n",
    "\n",
    "- ('DAI93865', 'FRO40251', '1.0')\n",
    "- ('GRO85051', 'FRO40251', '0.999176276771')\n",
    "- ('GRO38636', 'FRO40251', '0.990654205607')\n",
    "- ('ELE12951', 'FRO40251', '0.990566037736')\n",
    "- ('DAI88079', 'FRO40251', '0.986725663717')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DAI93865', 'FRO40251', '1.0')\n",
      "('GRO85051', 'FRO40251', '0.999176276771')\n",
      "('GRO38636', 'FRO40251', '0.990654205607')\n",
      "('ELE12951', 'FRO40251', '0.990566037736')\n",
      "('DAI88079', 'FRO40251', '0.986725663717')\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "with open(\"part-00000\") as output:\n",
    "    for line in output:\n",
    "        results_list.append((line.strip('\\n').split()[0], line.strip('\\n').split()[2], line.strip('\\n').split()[4]))\n",
    "\n",
    "# Note - I confirmed there are not ties, so we do not need to worry about lex. order\n",
    "for ranked_result in sorted(results_list,key=lambda x: x[2], reverse=True)[:5]:\n",
    "    print ranked_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell can be used to delete old output to allow re-run of any Hadoop script.\n",
    "#!hadoop fs -rm -r ./W261/Out/HW3_1_a\n",
    "#!hadoop fs -rm -r ./W261/Out/HW3_1_b\n",
    "#!hadoop fs -rm -r ./W261/Out/HW3_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:silver\"><b>HW3.3 [Note - We were instructed to skip this problem]</b></span>\n",
    "\n",
    "<span style=\"color:silver\">Benchmark your results using the pyFIM implementation of the Apriori algorithm\n",
    "(Apriori - Association Rule Induction / Frequent Item Set Mining implemented by Christian Borgelt). </span>\n",
    "<span style=\"color:silver\">You can download pyFIM from here: </span>\n",
    "\n",
    "http://www.borgelt.net/pyfim.html\n",
    "\n",
    "<span style=\"color:silver\">Comment on the results from both implementations (your Hadoop MapReduce of apriori versus pyFIM) \n",
    "in terms of results and execution times.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:silver\"><b>HW3.4</b> (Conceptual Exercise)</span>\n",
    "\n",
    "<span style=\"color:silver\">Suppose that you wished to perform the Apriori algorithm once again,\n",
    "though this time now with the goal of listing the top 5 rules with corresponding confidence scores \n",
    "in decreasing order of confidence score for itemsets of size 3 using Hadoop MapReduce.\n",
    "A rule is now of the form: </span>\n",
    "\n",
    "<span style=\"color:silver\">(item1, item2) ⇒ item3 </span>\n",
    "\n",
    "<span style=\"color:silver\">Recall that the Apriori algorithm is iterative for increasing itemset size,\n",
    "working off of the frequent itemsets of the previous size to explore \n",
    "ONLY the NECESSARY subset of a large combinatorial space. \n",
    "Describe how you might design a framework to perform this exercise.</span>\n",
    "\n",
    "<span style=\"color:silver\">In particular, focus on the following:</span>\n",
    "  — <span style=\"color:silver\">map-reduce steps required</span>\n",
    "  - <span style=\"color:silver\">enumeration of item sets and filtering for frequent candidates</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"><b>Answer</b></span>:\n",
    "\n",
    "If we were still restricted to a single mapper/reducer pair, we would continue in the manner set forth above. We would need to violate the Apriori algorithm by creating pairs (or stripes) for all possible 3-item sets, then in the reducer we would only process those 3-item sets comprised of passing 2-item sets. In that case, the data from the mapper would leverage an additional level of inverted ordering, outputting tuples as follows:\n",
    "\n",
    "- (\\*, \\*, a)\n",
    "- (\\*, a, b)\n",
    "- (a, b, c)\n",
    "\n",
    "From this, can count all the a, b terms via the pre-sorted *, a, b\n",
    "\n",
    "However, this thought exercise allows us to move beyond this simple limitation.\n",
    "\n",
    "To run the Apriori algorithem using multiple Map-Reduce passes, I would first install a package such as MrJob which makes such iterative approaches more intuitive to develop. I would then, on the first pass, determine which tuples passed the threshold as was done in problem 3.2 above. The output from that reducer would be a single line file listing the tuples that passed the check as shown below:\n",
    "\n",
    "- DAI93865 FRO40251 [tab] GRO85051 FRO40251  [tab] GRO38636 FRO40251 (etc.)\n",
    "\n",
    "This file (which could also be stored as a list and passed to the next iteration) would be loaded into the mappers on the second iteration and saved as a dictionary. Because these list of tuples have been filtered using the threshold, it is reasonable to believe they would fit in memory (for extremely large datasets this assumption could be revisted). Then, when processing in the mapper, only pairs present in the dictionary would be output.\n",
    "\n",
    "This process could be repeated as many times as needed to create larger itemsets via Apriori.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This concludes HW 3.0. Thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
